{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c53829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "pipeline = pipeline(\n",
    "    task=\"text2text-generation\",\n",
    "    model=\"google/flan-t5-base\",\n",
    "    device=-1\n",
    "    )\n",
    "output = pipeline(\"translate english to russian: The weather is nice today\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f5f9ac",
   "metadata": {},
   "source": [
    "do the pip install torch & pip install transform in code cell, if ur using in google colab & if ur using in cusor ai just give it the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe5ce8",
   "metadata": {},
   "source": [
    "to run the code in .py files use this method, go to terminal and type python filename.py. in my case it's python dummy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6beb638",
   "metadata": {},
   "source": [
    "Note:\n",
    "If you're running on CPU, keep device=-1.\n",
    "If you're using a GPU (like CUDA), make sure your system is set up for it and then use device=0.\n",
    "\n",
    "\n",
    "CPU AND GPU in simple terms:\n",
    "\n",
    "What are CPU and GPU?\n",
    "CPU\tThe main processor in your computer. It's good at doing a few tasks at a time.\n",
    "GPU\tA special processor (often used for gaming or AI). It can do many tasks at once, so it's much faster for AI tasks like translation, image generation, etc.\n",
    "\n",
    "In Transformers (and PyTorch):\n",
    "When you run a model, you can tell it where to run:\n",
    "\n",
    "device=0\tUse GPU #0 (first GPU) – fast, but only works if you have a supported GPU (like NVIDIA + CUDA).\n",
    "device=-1\tUse CPU – slower, but works on all computers (no special setup needed).\n",
    "\n",
    "Which one should you use?\n",
    "\n",
    "If you're not sure, just use:\n",
    "device=-1  # Always safe, uses CPU\n",
    "\n",
    "If you have a good GPU (NVIDIA) and want speed:\n",
    "Make sure PyTorch with CUDA is installed.\n",
    "Then use:\n",
    "device=0  # Uses GPU (faster)\n",
    "\n",
    "To check cpu and gpu in my windows laptop\n",
    "\n",
    "Step 1: Check Your CPU\n",
    "Option 1: Use Task Manager\n",
    "Press Ctrl + Shift + Esc to open Task Manager.\n",
    "Click the Performance tab.\n",
    "Click CPU on the left side.\n",
    "You'll see your CPU name at the top-right (e.g., Intel i5, AMD Ryzen).\n",
    "\n",
    "Step 2: Check Your GPU\n",
    "Option 1: In Task Manager (Easiest)\n",
    "In Task Manager, go to the Performance tab.\n",
    "Click GPU 0 on the left.\n",
    "You’ll see your GPU name (e.g., Intel UHD, NVIDIA GeForce).\n",
    "\n",
    "If it says Intel or AMD Radeon only, you likely don't have a high-performance GPU for AI.\n",
    "If it says NVIDIA GeForce GTX/RTX, then you do!\n",
    "\n",
    "Option 2: Use Command Line\n",
    "\n",
    "Press Win + R, type cmd, and press Enter.\n",
    "Type this command and hit Enter:\n",
    "wmic path win32_VideoController get name\n",
    "\n",
    "This will list your GPU(s).\n",
    "\n",
    "How to Know if Your GPU Supports AI (CUDA)?\n",
    "\n",
    "If your GPU name includes \"NVIDIA GeForce GTX/RTX\" (e.g., RTX 3050, GTX 1650), then you can probably use it for AI — but you also need:\n",
    "CUDA-compatible driver\n",
    "PyTorch with CUDA installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e32cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
