{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRjzbPkqJQ2U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv(\"magic04.data\")"
      ],
      "metadata": {
        "id": "Ea6VwZNPJm4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [\"fLength\",\"fWidth\",\"fSize\",\"fConc\",\"fConc1\",\"fAsym\",\"fM3Long\",\"fM3Trans\",\"fAlpha\",\"fDist\",\"class\"]\n",
        "df = pd.read_csv(\"magic04.data\",names=cols)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "xzAIIuiBKPJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " here from \"flength\" to \"class\" called feature, feature are just thing that we are going to pass our model in order to help us predict the label,which in this case class column.\n",
        "\n",
        " here sample 0 has 10 different feature,so i have 10 different values that i can pass into some model."
      ],
      "metadata": {
        "id": "CW2aEMJWNZze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"class\"].unique()      #g-gamma h-hydra"
      ],
      "metadata": {
        "id": "dhdmdoLbMGTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"class\"]=(df['class']=='g').astype(int)"
      ],
      "metadata": {
        "id": "N7kuEiUdMuKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "-Jcpj1HHzYz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "hCVV7pLqzap7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for labels in cols[:-1]:\n",
        "  plt.hist(df[df[\"class\"]==1][labels],color='blue',label='gamma',alpha=0.7,density=True)\n",
        "  plt.hist(df[df[\"class\"]==0][labels],color='red',label='hydron',alpha=0.7,density=True)\n",
        "  plt.title(labels)\n",
        "  plt.ylabel(\"Probability\")\n",
        "  plt.xlabel(labels)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "C8GEdpE2zfz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Validate Test"
      ],
      "metadata": {
        "id": "6LHMjpog3C71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, validate, test = np.split(df.sample(frac=1), [int(0.6*len(df)), int(0.8*len(df))])      # splitting the dataframe, (df ...) this will shafapal my data, 0.6 means 60% data to validation, 0.8  means 80% data to test"
      ],
      "metadata": {
        "id": "S5NOvBni2OI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "if u seen in df.head() flength has over 100 but in fconc we have less than 100 ; the scale of numbers is way off and somethimes it will effect our results. so we need to scale this relative to mean and deviation of that specific column."
      ],
      "metadata": {
        "id": "k6SkSGY17qZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_dataset(dataframe):\n",
        "  X = dataframe[dataframe.cols[:-1]].values\n",
        "  y = dataframe[dataframe.cols[-1]].values\n",
        "\n",
        "  # import standardScalar\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  X = scaler.fit_transform(X)\n",
        "\n",
        "  # now we'll create the whole data as one 2d array to do that we need hstack\n",
        "  # we are stacking x and y\n",
        "  # numpy is very particular about dimensions\n",
        "  # here x is 2d but y 1d(vector), now to reshape y to 2d, we need call reshape\n",
        "  # and also need to pass dimensions\n",
        "  # here (-1,1) means make this 2d array where -1 means len(y)\n",
        "\n",
        "  data = np.hstack((X,np.reshape(y,(-1,1))))\n",
        "\n",
        "  return data, X, y"
      ],
      "metadata": {
        "id": "wFCKenpg5eOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train[train[\"class\"]==1]))  # gamma\n",
        "print(len(train[train[\"class\"]==0]))"
      ],
      "metadata": {
        "id": "VLbGqbyDAROe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we have 7k gamma and 4k hydra, this will become a issue, so we need to oversample our training data sets means to increase the number of values, so they match with each other.\n",
        "\n",
        "do reslove this we can import RandomOverSampler"
      ],
      "metadata": {
        "id": "lL_3mLBIB_uW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_dataset(dataframe, oversampler=False):\n",
        "  X = dataframe[dataframe.columns[:-1]].values\n",
        "  y = dataframe[dataframe.columns[-1]].values\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  X = scaler.fit_transform(X)\n",
        "\n",
        "  if oversampler:\n",
        "    ros = RandomOverSampler()\n",
        "    X,y = ros.fit_resample(X,y)   # says take less class and keep sampling from their to increase the dataset of that smaller class, so that they can match\n",
        "\n",
        "  data = np.hstack((X,np.reshape(y,(-1,1))))\n",
        "\n",
        "  return data, X, y"
      ],
      "metadata": {
        "id": "4cwnTfNSB5_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, X_train, y_train = scale_dataset(train, oversampler= True)"
      ],
      "metadata": {
        "id": "hHTz4QbaGqTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "id": "40g6QZlJMLxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_train)"
      ],
      "metadata": {
        "id": "iBAoonwZe8fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(y_train == 1)"
      ],
      "metadata": {
        "id": "_bra1St6e_JZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(y_train == 0)"
      ],
      "metadata": {
        "id": "20c377hffDDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "why switching to false for validate and test bcz, i have a data that i haven't seen yet, how does my sample perform on those and i don't want to oversample those.I want ot know if i have a random set of data that's unlabeled, can i trust my model. that's why not oversampling."
      ],
      "metadata": {
        "id": "KUhcIzW2k0dy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, X_train, y_train = scale_dataset(train, oversampler=True)\n",
        "validate, X_validate, y_vaildate = scale_dataset(validate, oversampler=False)\n",
        "test, X_test, y_test = scale_dataset(test, oversampler=False)"
      ],
      "metadata": {
        "id": "yCaL52mbfHRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we have our data properly formeted now will see different models."
      ],
      "metadata": {
        "id": "VmBSG3dMk2w5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN or K Nearest Neighbors"
      ],
      "metadata": {
        "id": "LLKQLelglRNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we use packages from sklearn, why we use packages, so we don't have to manually code all these things by ourself."
      ],
      "metadata": {
        "id": "FdBMgAiU63n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "Om81pftwlN-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_model = KNeighborsClassifier(n_neighbors=1) # asks how many neighbors we want here i gave only one.\n",
        "knn_model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "uxnwFpc77mvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = knn_model.predict(X_test)"
      ],
      "metadata": {
        "id": "Dey9N6SC8dan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "kyzeSdPm88e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "ZL0KlJ7S8-Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_pred,y_test))"
      ],
      "metadata": {
        "id": "QCsFvZFQ9AKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OSsykkgrCRbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy is 82%, what it is saying is we just look at what each of these new points what it's closed to then we got 82% accuracy, which means how many do we get right versus how many total are there.\n",
        "\n",
        "Now precision is we what saying class 0 and class 1, go to these site\n",
        "https://en.wikipedia.org/wiki/Precision_and_recall\n",
        "\n",
        "in the diagram, on left everything we know is actually trully +ve that we labeled +ve in our dataset and in right side is trully -ve.\n",
        "\n",
        "Now in circle we have things +ve were labeled +ve by our model. on left side they should have been +ve but they were labelled as -ve by our model.\n",
        "\n",
        "so precision is saying out of all the one labeled as positive, how many of them are true positive and recall saying out of all the ones labelled as +ve, how many do we actually get right.\n",
        "\n",
        "f1-score is a combination of precision and recall score, we will be looking into this bcz we have unbalanced test data set."
      ],
      "metadata": {
        "id": "P9UYtMZbCYR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Naive Bayes"
      ],
      "metadata": {
        "id": "qC-OMYwEQHSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "WLTJQBCnN-lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "IKqPIV0jQaLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = nb_model.predict(X_test)"
      ],
      "metadata": {
        "id": "RM9njIWGQo3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_pred,y_test))"
      ],
      "metadata": {
        "id": "kfz4HXHFRV8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "BqFJ8TI1S54I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr=LogisticRegression()\n",
        "lr.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "MeQEFLRgptLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=lr.predict(X_test)"
      ],
      "metadata": {
        "id": "VBQa3eaZrzcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_pred,y_test))"
      ],
      "metadata": {
        "id": "SA3L1Vp1sP4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural N/W"
      ],
      "metadata": {
        "id": "yu-cA4FJTDti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example for nn\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# eg data y:2x+1\n",
        "\n",
        "X = np.array([0,1,2,3,4],dtype=float)   # x is the input num\n",
        "y = np.array([1,3,5,7,9],dtype=float)   # y is the output we want our compuer to learn\n",
        "\n",
        "# creating simple model with 1 layer, 1 neuron\n",
        "\n",
        "model = tf.keras.Sequential([tf.keras.layers.Dense(units=1,input_shape=[1])  # 1 neuro(smallest brain possible in ML) and it takes only 1 input number and also neuro will figure out formula connecting x and y\n",
        "         ])\n",
        "\n",
        "# compile model\n",
        "\n",
        "model.compile(optimizer='sgd',loss='mean_squared_error')  # sgd(stochastic Gradient Descent), a method that slowly adjust the model to improve and loss='mean...', measures how wrong the model's guesses are so it knows how to improve.\n",
        "\n",
        "# Train model\n",
        "\n",
        "model.fit(X,y,epochs=500, verbose=0)  # epochs=500, the model will look at the data 500 times to learn, every time it looks, it makes a better guess. verbose=0 means print  all the process happens in output console but only print he result.\n",
        "\n",
        "# predict a new value\n",
        "\n",
        "print(model.predict(np.array([10.0]))) # a/c to equation y=2x+1, the result should be 21 or closest to our true value."
      ],
      "metadata": {
        "id": "SMFUopJVsajK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22284084-a750-4920-c2e7-129cdebece47"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "[[20.989529]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WJXkv0M7YWdA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3DyWh2IRTa0T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}