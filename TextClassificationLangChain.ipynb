{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "JwYGq7QQDDE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diff b/w library vs dependency vs components.\n",
        "\n",
        "Library --->\tA collection of pre-written code you can use. Here\tLangChain is the main library.\n",
        "Dependency ---> Any external library your project relies on to work.Here LangChain, FAISS, OpenAI's API, etc., are dependencies.\n",
        "Component/Module ---> Specific parts (tools, classes, or functions) inside a library.\tTextLoader, CharacterTextSplitter, RetrievalQA, etc. are components from LangChain.\n",
        "\n",
        "Example from your code:\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "LangChain → the library (and dependency).\n",
        "TextLoader → a component (or module) inside the LangChain library.\n",
        "\n",
        "Quick Analogy:\n",
        "Imagine LangChain is a car factory (library).\n",
        "Your project depends on it to build a car (it's a dependency).\n",
        "Inside the factory, you pick individual car parts (components) like engines, tires, or steering wheels — that’s like TextLoader or FAISS.\n",
        "\n",
        "\n",
        "1. from langchain.document_loaders import TextLoader\n",
        "\n",
        "What it does:\n",
        "Loads plain text documents from files so they can be processed by the AI.\n",
        "Simple terms:\n",
        "Think of this like reading the content of a .txt file so the AI can use it.\n",
        "\n",
        "2. from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "What it does:\n",
        "Splits large blocks of text into smaller chunks based on characters (like every 1000 characters).\n",
        "Simple terms:\n",
        "AI models work better with short pieces of text. This tool breaks long documents into bite-sized pieces.\n",
        "\n",
        "3. from langchain.vectorstores import FAISS\n",
        "\n",
        "What it does:\n",
        "Stores and searches vector representations (numerical form) of text using FAISS, a fast library for similarity search.\n",
        "Simple terms:\n",
        "It helps the AI remember and quickly find the most relevant pieces of your document when you ask a question.\n",
        "\n",
        "4. from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "What it does:\n",
        "Turns text into vectors (numbers) using OpenAI's embedding models.\n",
        "Simple terms:\n",
        "This is like converting sentences into a \"language of numbers\" that the AI can compare and understand.\n",
        "\n",
        "5. from langchain.chains import RetrievalQA\n",
        "\n",
        "What it does:\n",
        "Creates a question-answering system that retrieves relevant information from documents before answering.\n",
        "Simple terms:\n",
        "It lets you ask questions, and it will look through your loaded documents to give the best answer.\n",
        "\n",
        "6. from langchain.llms import OpenAI\n",
        "\n",
        "What it does:\n",
        "Connects to OpenAI’s language models (like GPT-4) to generate answers or responses.\n",
        "Simple terms:\n",
        "This is the brain of the system — the actual AI model that gives intelligent responses.\n",
        "\n",
        "Summary:\n",
        "\n",
        "You're building (or using) a system where:\n",
        "\n",
        "You load a document.\n",
        "Split it into chunks.\n",
        "Convert the chunks into a searchable format.\n",
        "Store them in a system that can quickly find relevant ones.\n",
        "Let a powerful AI model (like GPT-4) read the relevant parts.\n",
        "And answer questions about them."
      ],
      "metadata": {
        "id": "C6BKFmV9I8qG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-community"
      ],
      "metadata": {
        "id": "zaHxWVEgEBOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load multiple text files.\n",
        "files = [\"business-policy.txt\",\"lorem-ipsum.txt\",\"sports-policy.txt\"]"
      ],
      "metadata": {
        "id": "rsP-KDSDELv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files"
      ],
      "metadata": {
        "id": "n__o0zj9Scnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding all files we have\n",
        "documents = []\n",
        "for file in files:\n",
        "  loader = TextLoader(file)\n",
        "  documents.extend(loader.load())"
      ],
      "metadata": {
        "id": "fH6Yb38fSe8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A for loop is used when you want to repeat something a certain number of times — usually going through a list of items one by one.\n",
        "\n",
        "You use a for loop when you want to do something for every item in a group.\n",
        "For example:\n",
        "Print every name in a list.\n",
        "Go through all lines in a file.\n",
        "Add up all numbers in a list.\n",
        "Do something repeatedly a known number of times."
      ],
      "metadata": {
        "id": "q_MJkNygTs1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting text into smaller chunks\n",
        "splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "docs = splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "GWK1XbL0UN-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating embedding + vector db\n",
        "embedding = OpenAIEmbeddings()\n",
        "db = FAISS.from_documents(docs, embedding)"
      ],
      "metadata": {
        "id": "3s2TfRpBWEaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"skd-...\""
      ],
      "metadata": {
        "id": "7X6emTwDWa_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating retriveal-based QA chain\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=OpenAI(),\n",
        "    retriver=db.as_retriever()\n",
        ")"
      ],
      "metadata": {
        "id": "6AvuEg1FWrIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ask question to our files\n",
        "query = \" \"\n",
        "answer = qa.run(query)\n",
        "print(\"Answers : \",answer)"
      ],
      "metadata": {
        "id": "MWHFfHqAYj-X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}