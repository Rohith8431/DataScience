{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWsqsIyC8Pvu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import fitz  #fitz we'll extract text from PDF"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To import fitz, we need PyMuPDF library"
      ],
      "metadata": {
        "id": "B7Y7vXWt9EHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyMuPDF"
      ],
      "metadata": {
        "id": "MA9D2EkE8i-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting text from all pdf\n",
        "def extract_text_from_pdf(folder_path):\n",
        "  texts = []\n",
        "  for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "      pdf_pdf = os.path.join(folder_path, filename)\n",
        "      doc = fitz.open(pdf_pdf)\n",
        "      text = \" \"\n",
        "      for page in doc:\n",
        "        text += page.get_text(\"text\")\n",
        "  return text"
      ],
      "metadata": {
        "id": "lwC3hkCL9blp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extracting text from all pdf\n",
        "def extract_text_from_pdf(folder_path):\n",
        "  texts = []\n",
        "  for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "      pdf_pdf = os.path.join(folder_path, filename)\n",
        "      doc = fitz.open(pdf_path)\n",
        "      text = \" \"\n",
        "      for page in doc:\n",
        "        text += page.get_text(text)\n",
        "  return texts\n",
        "\n",
        "pdf_folder = [\"Rohith_CV.pdf\",\"budget_speech\"]\n",
        "document = extract_text_from_pdf(\"demoo/\")\n",
        "\n",
        "Problems in your code:\n",
        "\n",
        "Variable name mismatch:\n",
        "You wrote pdf_pdf = ... but then tried fitz.open(pdf_path) → should be consistent.\n",
        "\n",
        "Wrong get_text() usage:\n",
        "page.get_text(\"text\") is correct (not page.get_text(text)).\n",
        "\n",
        "Not appending text to texts list:\n",
        "Right now your function never returns any extracted content.\n",
        "\n",
        "pdf_folder usage:\n",
        "You set pdf_folder = [\"Rohith_CV.pdf\",\"budget_speech\"], but the function expects a folder path (string, not list).\n",
        "\n",
        "Fixed code:\n",
        "\n",
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "# Extract text from all PDFs in a folder\n",
        "def extract_text_from_pdf(folder_path):\n",
        "    texts = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(folder_path, filename)\n",
        "            doc = fitz.open(pdf_path)\n",
        "            text = \"\"\n",
        "            for page in doc:\n",
        "                text += page.get_text(\"text\")  # extract page text\n",
        "            texts.append(text)\n",
        "    return texts\n",
        "\n",
        "# Example usage\n",
        "pdf_folder = \"demoo/\"   # this should be a folder containing PDFs\n",
        "documents = extract_text_from_pdf(pdf_folder)\n",
        "\n",
        "print(\"Extracted\", len(documents), \"PDFs\")\n",
        "print(documents[0][:500])  # print first 500 chars of first PDF"
      ],
      "metadata": {
        "id": "vFzjKGwkGrIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_folder = (\"demo/\")"
      ],
      "metadata": {
        "id": "SQNFa-Z1Bnvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_folder"
      ],
      "metadata": {
        "id": "NtyTdcvzHY1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = extract_text_from_pdf(pdf_folder)"
      ],
      "metadata": {
        "id": "wkOK_OdNCP6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(document[1])"
      ],
      "metadata": {
        "id": "hyJJmQrqIoAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Extracted\", len(document), \"PDFsTotalLength\")"
      ],
      "metadata": {
        "id": "Lxvq5jcfCaA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(document[1][:250])"
      ],
      "metadata": {
        "id": "mTtix6dRH_Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you’re getting a blank string, that usually means the PDF doesn’t contain real text, but instead is made up of scanned images.\n",
        "\n",
        "Here’s why this happens:\n",
        "fitz (PyMuPDF), pdfplumber, or PyPDF2 can only extract text that’s actually encoded in the PDF.\n",
        "If your PDF is a scanned image, it has no embedded text → you’ll need OCR (Optical Character Recognition).\n",
        "\n",
        "Quick test:\n",
        "print(documents[0])\n",
        "If it’s empty → the PDF is image-based.\n",
        "\n",
        "OCR method for scanned PDFs\n",
        "You can use pytesseract + pdf2image\n",
        "\n",
        "Note:\n",
        "If your PDF is text-based, fitz should work.\n",
        "If it’s image-based, you need OCR."
      ],
      "metadata": {
        "id": "VlkqxlKMKgaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytesseract pdf2image pillow"
      ],
      "metadata": {
        "id": "JGfLCR_6IUVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "import pytesseract"
      ],
      "metadata": {
        "id": "zIZZ0SaHKLHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_with_ocr(pdf_path):\n",
        "  pages = convert_from_path(pdf_path)\n",
        "  text = \" \"\n",
        "  for page in pages:\n",
        "    text+=pytesseract.image_to_string(page)\n",
        "  return text"
      ],
      "metadata": {
        "id": "O6jSgljIKXh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"demo/Rohith_CV.pdf\""
      ],
      "metadata": {
        "id": "3IuasagkLrMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ocr_text = extract_text_with_ocr(pdf_path)"
      ],
      "metadata": {
        "id": "10Fz9VJVL2I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "that error means pdf2image is working, but Poppler (the backend tool it needs) isn’t installed on your system.\n",
        "\n",
        "If installing Poppler is a hassle, you can skip pdf2image and directly use PyMuPDF’s built-in OCR (since version 1.23.0)"
      ],
      "metadata": {
        "id": "PM7HPKoNM6HR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = fitz.open(\"demo/Rohith_CV.pdf\")\n",
        "text = \"\"\n",
        "for page in doc:\n",
        "  text += page.get_text(\"text\")\n",
        "  if not text.strip():\n",
        "    text += page.get_text(\"ocr\")\n",
        "print(text[:500])"
      ],
      "metadata": {
        "id": "11g7oOWTMAbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "budget_speech.pdf → text-based (works directly with fitz).\n",
        "Rohith_CV.pdf → image-based (needs OCR).\n",
        "sk.pdf → unknown (we need to detect if text exists, otherwise fallback to OCR)."
      ],
      "metadata": {
        "id": "p-IHYy5HNaXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_auto(pdf_path):\n",
        "  doc = fitz.open(pdf_path)\n",
        "  text=\"\"\n",
        "  ocr_needed = False\n",
        "\n",
        "  for page in doc:\n",
        "    page_text = page.get_text(\"text\")\n",
        "    if page_text.strip():\n",
        "      text += page_text\n",
        "    else:\n",
        "      ocr_needed = True\n",
        "\n",
        "  doc.close()\n",
        "\n",
        "  if ocr_needed:\n",
        "    print(f\"Using OCR for: {pdf_path}\")\n",
        "    pages = convert_from_path(pdf_path)\n",
        "    for img_pages in pages:\n",
        "      text+=pytesseract.image_to_string(img_pages)\n",
        "\n",
        "  return text\n"
      ],
      "metadata": {
        "id": "Vmue663FNr1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"demo\"\n",
        "all_text = {}"
      ],
      "metadata": {
        "id": "qv9cPwCFSiEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in os.listdir(folder):\n",
        "  if file.endswith(\".pdf\"):\n",
        "    pdf_path = os.path.join(folder, file)\n",
        "    extracted_text = extract_text_auto(pdf_path)\n",
        "    all_text[file] = extracted_text\n",
        "    print(f\"Extracted {len(extracted_text)} characters from {file}\")"
      ],
      "metadata": {
        "id": "9eAw1I1FSwRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here’s what’s happening in your run:\n",
        "Rohith_CV.pdf → OCR worked fine (3114 characters).\n",
        "sk.pdf → text extraction worked fine (4940 characters).\n",
        "budget_speech.pdf → wrongly went to OCR path, then failed because Poppler (pdfinfo) is missing.\n",
        "That means budget_speech.pdf actually does have text, but our function mistakenly decided it needed OCR.\n",
        "\n",
        "We don’t want to call pdf2image at all unless the PDF really has no text anywhere.\n",
        "Right now, if just one page is empty, we switch to OCR for the whole file → that’s why budget speech triggered OCR unnecessarily."
      ],
      "metadata": {
        "id": "F3JklvvAOSgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Improved Function (OCR only if entire file is empty)\n",
        "import fitz  # PyMuPDF\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "def extract_text_auto(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "\n",
        "    # Try extracting text normally from all pages\n",
        "    for page in doc:\n",
        "        page_text = page.get_text(\"text\")\n",
        "        if page_text.strip():\n",
        "            text += page_text\n",
        "\n",
        "    doc.close()\n",
        "\n",
        "    # If no text found at all → fallback to OCR\n",
        "    if not text.strip():\n",
        "        print(f\"⚡ Using OCR for: {pdf_path}\")\n",
        "        pages = convert_from_path(pdf_path)\n",
        "        for img_page in pages:\n",
        "            text += pytesseract.image_to_string(img_page)\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "kXj9ElahUkUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why this works\n",
        "\n",
        "budget_speech.pdf → has text → will NOT trigger OCR anymore.\n",
        "Rohith_CV.pdf → no text at all → will trigger OCR.\n",
        "sk.pdf → already worked with text → stays the same."
      ],
      "metadata": {
        "id": "46QFKOhcPLZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder = \"demo\"\n",
        "all_text = {}"
      ],
      "metadata": {
        "id": "_ufiyG8nVJRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in os.listdir(folder):\n",
        "  if file.endswith(\".pdf\"):\n",
        "    pdf_path = os.path.join(folder, file)\n",
        "    extracted_text = extract_text_auto(pdf_path)\n",
        "    all_text[file] = extracted_text\n",
        "    print(f\"Extracted {len(extracted_text)} characters from {file}\")"
      ],
      "metadata": {
        "id": "Z2CwYofMVOTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now save results into .txt\n",
        "for fname, content in all_text.items():\n",
        "  with open(fname.replace(\".pdf\",\".txt\"),\"w\",encoding=\"utf-8\") as f:f.write(content)"
      ],
      "metadata": {
        "id": "jEaoCn8SVQqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "uFhYUfFEXeko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = list(all_text.values())"
      ],
      "metadata": {
        "id": "rY9KD_hCYzOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_docs = [doc.lower().strip() for doc in documents]"
      ],
      "metadata": {
        "id": "ps2NlstJZF-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "iuJ0ObqqYAz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JoWR172lRpUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = vectorizer.fit_transform(processed_docs)"
      ],
      "metadata": {
        "id": "cLaVT2tiYGL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"shape of TF-IDF matrix:\",X.shape)"
      ],
      "metadata": {
        "id": "LO823yJiZbMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.get_feature_names_out()[:50])"
      ],
      "metadata": {
        "id": "b915wvpGZyTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarities = cosine_similarity(X)\n",
        "print(similarities)"
      ],
      "metadata": {
        "id": "BHweZ9vyahhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(\n",
        "    stop_words=\"english\",\n",
        "    token_pattern=r\"[a-zA-Z]{2,}\",\n",
        "    max_features=5000\n",
        ")\n",
        "\n",
        "X = vectorizer.fit_transform(processed_docs)"
      ],
      "metadata": {
        "id": "1z4cc3bfbRWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.get_feature_names_out()[:50])"
      ],
      "metadata": {
        "id": "qc4veZu4c261"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = list(all_text.keys())   # same order as documents"
      ],
      "metadata": {
        "id": "by8CwN7wdC6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "def top_keywords_for_doc(doc_index, top_n=10):\n",
        "    row = X[doc_index].toarray().flatten()   # TF-IDF values for that doc\n",
        "    top_indices = row.argsort()[::-1][:top_n]\n",
        "    keywords = [(feature_names[i], row[i]) for i in top_indices]\n",
        "    return keywords\n",
        "\n",
        "# Example: top keywords for each file\n",
        "for i, fname in enumerate(filenames):\n",
        "    print(f\"\\n {fname}\")\n",
        "    print(top_keywords_for_doc(i, top_n=10))\n"
      ],
      "metadata": {
        "id": "amL4W35cet81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarities = cosine_similarity(X)\n",
        "\n",
        "# Example: compare first doc with others\n",
        "print(\"Similarity of first doc vs all:\")\n",
        "for i, fname in enumerate(filenames):\n",
        "    print(f\"{filenames[2]} vs {fname}: {similarities[2][i]:.3f}\")\n"
      ],
      "metadata": {
        "id": "98QebE3SfS1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"machine learning\"\n",
        "query_vec = vectorizer.transform([query])\n",
        "\n",
        "similarities = cosine_similarity(query_vec, X).flatten()\n",
        "\n",
        "# Sort by relevance\n",
        "results = sorted(zip(filenames, similarities), key=lambda x: -x[1])\n",
        "\n",
        "print(\"\\n🔎 Search results for:\", query)\n",
        "for fname, score in results:\n",
        "    print(f\"{fname}: {score:.3f}\")\n"
      ],
      "metadata": {
        "id": "teG-7S6pfkbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"machine\" in vectorizer.get_feature_names_out())\n",
        "print(\"learning\" in vectorizer.get_feature_names_out())\n",
        "print(\"machine learning\" in all_text[\"Rohith_CV.pdf\"].lower())"
      ],
      "metadata": {
        "id": "D6Dd9Wvbfzvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-yXYQtKtgMu_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}